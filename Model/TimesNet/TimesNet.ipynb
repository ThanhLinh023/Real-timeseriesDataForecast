{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c8b6039-1be6-459a-ba34-2d24dfd17257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.fft\n",
    "from layers.Embed import DataEmbedding\n",
    "from layers.Conv_Blocks import Inception_Block_V1\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a05b4c59-8408-4532-af3d-be4df8a0f5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>3/1/2019</td>\n",
       "      <td>1314.460</td>\n",
       "      <td>1292.765</td>\n",
       "      <td>1315.105</td>\n",
       "      <td>1290.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>3/2/2019</td>\n",
       "      <td>1292.765</td>\n",
       "      <td>1292.765</td>\n",
       "      <td>1292.765</td>\n",
       "      <td>1292.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>3/3/2019</td>\n",
       "      <td>1292.765</td>\n",
       "      <td>1292.765</td>\n",
       "      <td>1292.765</td>\n",
       "      <td>1292.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>3/4/2019</td>\n",
       "      <td>1295.910</td>\n",
       "      <td>1286.710</td>\n",
       "      <td>1297.105</td>\n",
       "      <td>1283.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>3/5/2019</td>\n",
       "      <td>1287.410</td>\n",
       "      <td>1287.775</td>\n",
       "      <td>1289.550</td>\n",
       "      <td>1281.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/22/2024</td>\n",
       "      <td>2181.340</td>\n",
       "      <td>2165.400</td>\n",
       "      <td>2186.050</td>\n",
       "      <td>2157.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/23/2024</td>\n",
       "      <td>2165.400</td>\n",
       "      <td>2165.400</td>\n",
       "      <td>2165.400</td>\n",
       "      <td>2165.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/24/2024</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2165.990</td>\n",
       "      <td>2167.890</td>\n",
       "      <td>2165.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/25/2024</td>\n",
       "      <td>2166.820</td>\n",
       "      <td>2172.300</td>\n",
       "      <td>2181.000</td>\n",
       "      <td>2163.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/26/2024</td>\n",
       "      <td>2172.680</td>\n",
       "      <td>2179.120</td>\n",
       "      <td>2199.880</td>\n",
       "      <td>2167.970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1694 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date      Open     Close      High       Low\n",
       "1693   3/1/2019  1314.460  1292.765  1315.105  1290.355\n",
       "1692   3/2/2019  1292.765  1292.765  1292.765  1292.765\n",
       "1691   3/3/2019  1292.765  1292.765  1292.765  1292.765\n",
       "1690   3/4/2019  1295.910  1286.710  1297.105  1283.160\n",
       "1689   3/5/2019  1287.410  1287.775  1289.550  1281.460\n",
       "...         ...       ...       ...       ...       ...\n",
       "4     3/22/2024  2181.340  2165.400  2186.050  2157.450\n",
       "3     3/23/2024  2165.400  2165.400  2165.400  2165.400\n",
       "2     3/24/2024     0.000  2165.990  2167.890  2165.300\n",
       "1     3/25/2024  2166.820  2172.300  2181.000  2163.970\n",
       "0     3/26/2024  2172.680  2179.120  2199.880  2167.970\n",
       "\n",
       "[1694 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../Dataset/Gold.csv')\n",
    "df = df.sort_index(ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a74ad98-b169-419c-a968-9ad1fed5cad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xây dựng TimesBlock\n",
    "class TimesBlock(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(TimesBlock, self).__init__()\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.k = configs.top_k\n",
    "        # parameter-efficient design\n",
    "        self.conv = nn.Sequential(\n",
    "            Inception_Block_V1(configs.d_model, configs.d_ff,\n",
    "                               num_kernels=configs.num_kernels),\n",
    "            nn.GELU(),\n",
    "            Inception_Block_V1(configs.d_ff, configs.d_model,\n",
    "                               num_kernels=configs.num_kernels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, N = x.size()\n",
    "        period_list, period_weight = FFT_for_Period(x, self.k)\n",
    "\n",
    "        res = []\n",
    "        for i in range(self.k):\n",
    "            period = period_list[i]\n",
    "            # padding\n",
    "            if (self.seq_len + self.pred_len) % period != 0:\n",
    "                length = (\n",
    "                                 ((self.seq_len + self.pred_len) // period) + 1) * period\n",
    "                padding = torch.zeros([x.shape[0], (length - (self.seq_len + self.pred_len)), x.shape[2]]).to(x.device)\n",
    "                out = torch.cat([x, padding], dim=1)\n",
    "            else:\n",
    "                length = (self.seq_len + self.pred_len)\n",
    "                out = x\n",
    "            # reshape\n",
    "            out = out.reshape(B, length // period, period,\n",
    "                              N).permute(0, 3, 1, 2).contiguous()\n",
    "            # 2D conv: from 1d Variation to 2d Variation\n",
    "            out = self.conv(out)\n",
    "            # reshape back\n",
    "            out = out.permute(0, 2, 3, 1).reshape(B, -1, N)\n",
    "            res.append(out[:, :(self.seq_len + self.pred_len), :])\n",
    "        res = torch.stack(res, dim=-1)\n",
    "        # adaptive aggregation\n",
    "        period_weight = F.softmax(period_weight, dim=1)\n",
    "        period_weight = period_weight.unsqueeze(\n",
    "            1).unsqueeze(1).repeat(1, T, N, 1)\n",
    "        res = torch.sum(res * period_weight, -1)\n",
    "        # residual connection\n",
    "        res = res + x\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa274db-8bc4-4ff0-8524-84e96c29daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FFT\n",
    "def FFT_for_Period(x, k=2):\n",
    "    # xf shape [B, T, C], denoting the amplitude of frequency(T) given the datapiece at B,N\n",
    "    xf = torch.fft.rfft(x, dim=1) \n",
    "\n",
    "    # find period by amplitudes: here we assume that the periodic features are basically constant\n",
    "    # in different batch and channel, so we mean out these two dimensions, getting a list frequency_list with shape[T] \n",
    "    # each element at pos t of frequency_list denotes the overall amplitude at frequency (t)\n",
    "    frequency_list = abs(xf).mean(0).mean(-1) \n",
    "    frequency_list[0] = 0\n",
    "\n",
    "    #by torch.topk(),we can get the biggest k elements of frequency_list, and its positions(i.e. the k-main frequencies in top_list)\n",
    "    _, top_list = torch.topk(frequency_list, k)\n",
    "\n",
    "    #Returns a new Tensor 'top_list', detached from the current graph.\n",
    "    #The result will never require gradient.Convert to a numpy instance\n",
    "    top_list = top_list.detach().cpu().numpy()\n",
    "     \n",
    "    #period:a list of shape [top_k], recording the periods of mean frequencies respectively\n",
    "    period = x.shape[1] // top_list\n",
    "\n",
    "    #Here,the 2nd item returned has a shape of [B, top_k],representing the biggest top_k amplitudes \n",
    "    # for each piece of data, with N features being averaged.\n",
    "    return period, abs(xf).mean(-1)[:, top_list] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae92005-7d36-4a3a-93f9-59377124ce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dự báo\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(Model, self).__init__()\n",
    "        self.configs = configs\n",
    "        self.task_name = configs.task_name\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.label_len = configs.label_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.model = nn.ModuleList([TimesBlock(configs)\n",
    "                                    for _ in range(configs.e_layers)])\n",
    "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                           configs.dropout)\n",
    "        self.layer = configs.e_layers\n",
    "        self.layer_norm = nn.LayerNorm(configs.d_model)\n",
    "        if self.task_name == 'long_term_forecast' or self.task_name == 'short_term_forecast':\n",
    "            self.predict_linear = nn.Linear(\n",
    "                self.seq_len, self.pred_len + self.seq_len)\n",
    "            self.projection = nn.Linear(\n",
    "                configs.d_model, configs.c_out, bias=True)\n",
    "        if self.task_name == 'imputation' or self.task_name == 'anomaly_detection':\n",
    "            self.projection = nn.Linear(\n",
    "                configs.d_model, configs.c_out, bias=True)\n",
    "        if self.task_name == 'classification':\n",
    "            self.act = F.gelu\n",
    "            self.dropout = nn.Dropout(configs.dropout)\n",
    "            self.projection = nn.Linear(\n",
    "                configs.d_model * configs.seq_len, configs.num_class)\n",
    "\n",
    "    def forecast(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "        # Normalization from Non-stationary Transformer\n",
    "        means = x_enc.mean(1, keepdim=True).detach()\n",
    "        x_enc = x_enc - means\n",
    "        stdev = torch.sqrt(\n",
    "            torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)\n",
    "        x_enc /= stdev\n",
    "\n",
    "        # embedding\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)  # [B,T,C]\n",
    "        enc_out = self.predict_linear(enc_out.permute(0, 2, 1)).permute(\n",
    "            0, 2, 1)  # align temporal dimension\n",
    "        # TimesNet\n",
    "        for i in range(self.layer):\n",
    "            enc_out = self.layer_norm(self.model[i](enc_out))\n",
    "        # porject back\n",
    "        dec_out = self.projection(enc_out)\n",
    "\n",
    "        # De-Normalization from Non-stationary Transformer\n",
    "        dec_out = dec_out * \\\n",
    "                  (stdev[:, 0, :].unsqueeze(1).repeat(\n",
    "                      1, self.pred_len + self.seq_len, 1))\n",
    "        dec_out = dec_out + \\\n",
    "                  (means[:, 0, :].unsqueeze(1).repeat(\n",
    "                      1, self.pred_len + self.seq_len, 1))\n",
    "        return dec_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cbaf056-2a67-4146-922b-f4ade7103261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test\n",
    "def train(self, setting):  #setting is the args for this model training\n",
    "    #get train dataloader\n",
    "    train_data, train_loader = self._get_data(flag='train')\n",
    "    vali_data, vali_loader = self._get_data(flag='val')\n",
    "    test_data, test_loader = self._get_data(flag='test')\n",
    "\n",
    "    # set path of checkpoint for saving and loading model\n",
    "    path = os.path.join(self.args.checkpoints, setting)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    time_now = time.time()\n",
    "\n",
    "    train_steps = len(train_loader)\n",
    "\n",
    "    # EarlyStopping is typically a custom class or function that monitors the performance \n",
    "    # of a model during training, usually by tracking a certain metric (commonly validation \n",
    "    # loss or accuracy).It's a common technique used in deep learning to prevent overfitting \n",
    "    # during the training\n",
    "    early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n",
    "\n",
    "    #Optimizer and Loss Function Selection\n",
    "    model_optim = self._select_optimizer()\n",
    "    criterion = self._select_criterion()\n",
    "\n",
    "    # AMP training is a technique that uses lower-precision data types (e.g., float16) \n",
    "    # for certain computations to accelerate training and reduce memory usage.\n",
    "    if self.args.use_amp:  \n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "    for epoch in range(self.args.train_epochs):\n",
    "        iter_count = 0\n",
    "        train_loss = []\n",
    "        self.model.train()\n",
    "        epoch_time = time.time()\n",
    "\n",
    "        #begin training in this epoch\n",
    "        for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n",
    "            iter_count += 1\n",
    "            model_optim.zero_grad()\n",
    "            batch_x = batch_x.float().to(self.device)  #input features\n",
    "            batch_y = batch_y.float().to(self.device)  #target features\n",
    "\n",
    "            # _mark holds information about time-related features. Specifically, it is a \n",
    "            # tensor that encodes temporal information and is associated with the \n",
    "            # input data batch_x.\n",
    "            batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "            batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "            # decoder input(didn't use in TimesNet case)\n",
    "            dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
    "            dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "            # encoder - decoder\n",
    "            if self.args.use_amp: #in the case of TimesNet, use_amp should be False\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    # whether to output attention in ecoder,in TimesNet case is no\n",
    "                    if self.args.output_attention: \n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                    # model the input\n",
    "                    else:\n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "                    # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, \n",
    "                    # S:univariate predict univariate, MS:multivariate predict univariate'\n",
    "                    #if multivariate predict univariate',then output should be the last column of the decoder\n",
    "                    # output, so f_dim = -1 to only contain the last column, else is all columns\n",
    "                    f_dim = -1 if self.args.features == 'MS' else 0 \n",
    "                    outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                    batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "\n",
    "                    # calc loss\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    train_loss.append(loss.item())\n",
    "            else:  #similar to when use_amp is True\n",
    "                if self.args.output_attention:\n",
    "                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                else:\n",
    "                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "            # When train rounds attain some 100-multiple, print speed, left time, loss. etc feedback\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "                speed = (time.time() - time_now) / iter_count\n",
    "                left_time = speed * ((self.args.train_epochs - epoch) * train_steps - i)\n",
    "                print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "                iter_count = 0\n",
    "                time_now = time.time()\n",
    "\n",
    "            #BP\n",
    "            if self.args.use_amp:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(model_optim)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                model_optim.step()\n",
    "        \n",
    "        #This epoch comes to end, print information\n",
    "        print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
    "        train_loss = np.average(train_loss)\n",
    "\n",
    "        #run test and validation on current model\n",
    "        vali_loss = self.vali(vali_data, vali_loader, criterion)\n",
    "        test_loss = self.vali(test_data, test_loader, criterion)\n",
    "\n",
    "        #print train, test, vali loss information\n",
    "        print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
    "            epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
    "        \n",
    "        #Decide whether to trigger Early Stopping. if early_stop is true, it means that \n",
    "        #this epoch's training is now at a flat slope, so stop further training for this epoch.\n",
    "        early_stopping(vali_loss, self.model, path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        #adjust learning keys\n",
    "        adjust_learning_rate(model_optim, epoch + 1, self.args)\n",
    "    best_model_path = path + '/' + 'checkpoint.pth'\n",
    "\n",
    "    # loading the trained model's state dictionary from a saved checkpoint file \n",
    "    # located at best_model_path.\n",
    "    self.model.load_state_dict(torch.load(best_model_path))\n",
    "    return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66ef6602-2241-44b1-bb6a-8f73d009ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vali(self, vali_data, vali_loader, criterion):\n",
    "        total_loss = []\n",
    "\n",
    "        #evaluation mode\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(vali_loader):\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float()\n",
    "\n",
    "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                        else:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                else:\n",
    "                    if self.args.output_attention:\n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                    else:\n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "\n",
    "                pred = outputs.detach().cpu()\n",
    "                true = batch_y.detach().cpu()\n",
    "\n",
    "                loss = criterion(pred, true)\n",
    "\n",
    "                total_loss.append(loss)\n",
    "        total_loss = np.average(total_loss)\n",
    "        self.model.train()\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fdb8023-48b5-4c50-bb25-d4e094b96a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(self, setting, test=0):\n",
    "        test_data, test_loader = self._get_data(flag='test')\n",
    "        if test:\n",
    "            print('loading model')\n",
    "            self.model.load_state_dict(torch.load(os.path.join('./checkpoints/' + setting, 'checkpoint.pth')))\n",
    "\n",
    "        preds = []\n",
    "        trues = []\n",
    "        folder_path = './test_results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float().to(self.device)\n",
    "\n",
    "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                        else:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                else:\n",
    "                    if self.args.output_attention:\n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "\n",
    "                    else:\n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "                f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "                outputs = outputs.detach().cpu().numpy()\n",
    "                batch_y = batch_y.detach().cpu().numpy()\n",
    "\n",
    "                #inverse the data if scaled\n",
    "                if test_data.scale and self.args.inverse:\n",
    "                    outputs = test_data.inverse_transform(outputs)\n",
    "                    batch_y = test_data.inverse_transform(batch_y)\n",
    "\n",
    "                pred = outputs\n",
    "                true = batch_y\n",
    "\n",
    "                preds.append(pred)\n",
    "                trues.append(true)\n",
    "\n",
    "                #visualize one piece of data every 20\n",
    "                if i % 20 == 0:\n",
    "                    input = batch_x.detach().cpu().numpy()\n",
    "                    #the whole sequence\n",
    "                    gt = np.concatenate((input[0, :, -1], true[0, :, -1]), axis=0)\n",
    "                    pd = np.concatenate((input[0, :, -1], pred[0, :, -1]), axis=0)\n",
    "                    visual(gt, pd, os.path.join(folder_path, str(i) + '.pdf'))\n",
    "\n",
    "        preds = np.array(preds)\n",
    "        trues = np.array(trues)  # shape[batch_num, batch_size, pred_len, features]\n",
    "        print('test shape:', preds.shape, trues.shape)\n",
    "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
    "        print('test shape:', preds.shape, trues.shape)\n",
    "\n",
    "        # result save\n",
    "        folder_path = './results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        mae, mse, rmse, mape, mspe = metric(preds, trues)\n",
    "        print('mse:{}, mae:{}'.format(mse, mae))\n",
    "        f = open(\"result_long_term_forecast.txt\", 'a')\n",
    "        f.write(setting + \"  \\n\")\n",
    "        f.write('mse:{}, mae:{}'.format(mse, mae))\n",
    "        f.write('\\n')\n",
    "        f.write('\\n')\n",
    "        f.close()\n",
    "        \n",
    "        np.save(folder_path + 'metrics.npy', np.array([mae, mse, rmse, mape, mspe]))\n",
    "        np.save(folder_path + 'pred.npy', preds)\n",
    "        np.save(folder_path + 'true.npy', trues)\n",
    "\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be985d73-0359-444d-b495-43fd9a44b462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_data(self, flag):\n",
    "        data_set, data_loader = data_provider(self.args, flag)\n",
    "        return data_set, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e525c05c-bd9d-461d-9abe-1e59e0202df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_provider(args, flag):\n",
    "    Data = data_dict[args.data]  #data_provider\n",
    "\n",
    "    # time features encoding, options:[timeF, fixed, learned]\n",
    "    timeenc = 0 if args.embed != 'timeF' else 1\n",
    "\n",
    "    #test data provider\n",
    "    if flag == 'test':\n",
    "        shuffle_flag = False\n",
    "        drop_last = True\n",
    "        if args.task_name == 'anomaly_detection' or args.task_name == 'classification':\n",
    "            batch_size = args.batch_size\n",
    "\n",
    "        #Some tasks during the testing phase may require evaluating samples one at a time. \n",
    "        # This could be due to variations in sample sizes in the test data or because the \n",
    "        # evaluation process demands finer-grained results or different processing. \n",
    "        else:\n",
    "            batch_size = 1  # bsz=1 for evaluation\n",
    "\n",
    "        #freq for time features encoding, \n",
    "        # options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly,\n",
    "        #  m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "        freq = args.freq\n",
    "    else:\n",
    "        shuffle_flag = True\n",
    "        drop_last = True\n",
    "        batch_size = args.batch_size  # bsz for train and valid\n",
    "        freq = args.freq\n",
    "\n",
    "    if args.task_name == 'anomaly_detection':\n",
    "        drop_last = False\n",
    "        data_set = Data(\n",
    "            root_path=args.root_path, #root path of the data file\n",
    "            win_size=args.seq_len,    #input sequence length\n",
    "            flag=flag,\n",
    "        )\n",
    "        print(flag, len(data_set))\n",
    "        data_loader = DataLoader(\n",
    "            data_set,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle_flag,\n",
    "            num_workers=args.num_workers,#data loader num workers\n",
    "            drop_last=drop_last)\n",
    "        return data_set, data_loader\n",
    "\n",
    "    elif args.task_name == 'classification':\n",
    "        drop_last = False\n",
    "        data_set = Data(\n",
    "            root_path=args.root_path,\n",
    "            flag=flag,\n",
    "        )\n",
    "\n",
    "        data_loader = DataLoader(\n",
    "            data_set,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle_flag,\n",
    "            num_workers=args.num_workers,\n",
    "            drop_last=drop_last,\n",
    "            collate_fn=lambda x: collate_fn(x, max_len=args.seq_len) \n",
    "            #define some limits to collate pieces of data into batches\n",
    "        )\n",
    "        return data_set, data_loader\n",
    "    else:\n",
    "        if args.data == 'm4':\n",
    "            drop_last = False\n",
    "        data_set = Data(\n",
    "            root_path=args.root_path, #eg.  ./data/ETT/\n",
    "            data_path=args.data_path, #eg.  ETTh1.csv\n",
    "            flag=flag,\n",
    "            size=[args.seq_len, args.label_len, args.pred_len],\n",
    "            features=args.features,   #forecasting task, options:[M, S, MS]; \n",
    "            # M:multivariate predict multivariate, S:univariate predict univariate,\n",
    "            # MS:multivariate predict univariate\n",
    "            \n",
    "            target=args.target,       #target feature in S or MS task\n",
    "            timeenc=timeenc,\n",
    "            freq=freq,\n",
    "            seasonal_patterns=args.seasonal_patterns\n",
    "        )\n",
    "        print(flag, len(data_set))\n",
    "        data_loader = DataLoader(\n",
    "            data_set,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle_flag,\n",
    "            num_workers=args.num_workers,\n",
    "            drop_last=drop_last)\n",
    "        return data_set, data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7fa9c2c-2b6b-435d-8017-02c63f8add08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, root_path, flag='train', size=None,\n",
    "             features='S', data_path='ETTh1.csv',\n",
    "             target='OT', scale=True, timeenc=0, freq='h', seasonal_patterns=None):\n",
    "    # size [seq_len, label_len, pred_len]\n",
    "    # info\n",
    "    if size == None:\n",
    "        self.seq_len = 24 * 4 * 4\n",
    "        self.label_len = 24 * 4\n",
    "        self.pred_len = 24 * 4\n",
    "    else:\n",
    "        self.seq_len = size[0]\n",
    "        self.label_len = size[1]\n",
    "        self.pred_len = size[2]\n",
    "    # init\n",
    "    assert flag in ['train', 'test', 'val']\n",
    "    type_map = {'train': 0, 'val': 1, 'test': 2}\n",
    "    self.set_type = type_map[flag]\n",
    "    self.features = features\n",
    "    self.target = target\n",
    "    self.scale = scale\n",
    "    self.timeenc = timeenc\n",
    "    self.freq = freq\n",
    "    self.root_path = root_path\n",
    "    self.data_path = data_path\n",
    "    \n",
    "    # After initialization, call __read_data__() to manage the data file.\n",
    "    self.__read_data__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c07c979-90c9-4beb-bb84-f9fa5dd20888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __read_data__(self):\n",
    "    self.scaler = StandardScaler()\n",
    "\n",
    "    #get raw data from path\n",
    "    df_raw = pd.read_csv(os.path.join(self.root_path,\n",
    "                                      self.data_path))\n",
    "\n",
    "    # split data set into train, vali, test. border1 is the left border and border2 is the right.\n",
    "    # Once flag(train, vali, test) is determined, __read_data__ will return certain part of the dataset.\n",
    "    border1s = [0, 12 * 30 * 24 - self.seq_len, 12 * 30 * 24 + 4 * 30 * 24 - self.seq_len]\n",
    "    border2s = [12 * 30 * 24, 12 * 30 * 24 + 4 * 30 * 24, 12 * 30 * 24 + 8 * 30 * 24]\n",
    "    border1 = border1s[self.set_type]\n",
    "    border2 = border2s[self.set_type]\n",
    "\n",
    "    #decide which columns to select\n",
    "    if self.features == 'M' or self.features == 'MS':\n",
    "        cols_data = df_raw.columns[1:] # column name list (remove 'date')\n",
    "        df_data = df_raw[cols_data]  #remove the first column, which is time stamp info\n",
    "    elif self.features == 'S':\n",
    "        df_data = df_raw[[self.target]] # target column\n",
    "\n",
    "    #scale data by the scaler that fits training data\n",
    "    if self.scale:\n",
    "        train_data = df_data[border1s[0]:border2s[0]]\n",
    "        #train_data.values: turn pandas DataFrame into 2D numpy\n",
    "        self.scaler.fit(train_data.values)  \n",
    "        data = self.scaler.transform(df_data.values)\n",
    "    else:\n",
    "        data = df_data.values \n",
    "    \n",
    "    #time stamp:df_stamp is a object of <class 'pandas.core.frame.DataFrame'> and\n",
    "    # has one column called 'date' like 2016-07-01 00:00:00\n",
    "    df_stamp = df_raw[['date']][border1:border2]\n",
    "    \n",
    "    # Since the date format is uncertain across different data file, we need to \n",
    "    # standardize it so we call func 'pd.to_datetime'\n",
    "    df_stamp['date'] = pd.to_datetime(df_stamp.date) \n",
    "\n",
    "    if self.timeenc == 0:  #time feature encoding is fixed or learned\n",
    "        df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
    "        df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
    "        df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
    "        df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
    "        #now df_frame has multiple columns recording the month, day etc. time stamp\n",
    "        # next we delete the 'date' column and turn 'DataFrame' to a list\n",
    "        data_stamp = df_stamp.drop(['date'], 1).values\n",
    "\n",
    "    elif self.timeenc == 1: #time feature encoding is timeF\n",
    "        '''\n",
    "         when entering this branch, we choose arg.embed as timeF meaning we want to \n",
    "         encode the temporal info. 'freq' should be the smallest time step, and has \n",
    "          options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "         So you should check the timestep of your data and set 'freq' arg. \n",
    "         After the time_features encoding, each date info format will be encoded into \n",
    "         a list, with each element denoting the relative position of this time point\n",
    "         (e.g. Day of Week, Day of Month, Hour of Day) and each normalized within scope[-0.5, 0.5]\n",
    "         '''\n",
    "        data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
    "        data_stamp = data_stamp.transpose(1, 0)\n",
    "        \n",
    "    \n",
    "    # data_x and data_y are same copy of a certain part of data\n",
    "    self.data_x = data[border1:border2]\n",
    "    self.data_y = data[border1:border2]\n",
    "    self.data_stamp = data_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dacf496-1b10-4288-b67b-e64d60c568db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getitem__(self, index):\n",
    "    #given an index, calculate the positions after this index to truncate the dataset\n",
    "    s_begin = index\n",
    "    s_end = s_begin + self.seq_len\n",
    "    r_begin = s_end - self.label_len\n",
    "    r_end = r_begin + self.label_len + self.pred_len\n",
    "\n",
    "    #input and output sequence\n",
    "    seq_x = self.data_x[s_begin:s_end]\n",
    "    seq_y = self.data_y[r_begin:r_end]\n",
    "\n",
    "    #time mark\n",
    "    seq_x_mark = self.data_stamp[s_begin:s_end]\n",
    "    seq_y_mark = self.data_stamp[r_begin:r_end]\n",
    "\n",
    "    return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
    "\n",
    "def __len__(self):\n",
    "    return len(self.data_x) - self.seq_len - self.pred_len + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0f525e-698a-420f-8db1-d0f899f38975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
